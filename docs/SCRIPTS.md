# üìã GUIDE DES SCRIPTS NPM

Ce document explique en d√©tail tous les scripts npm disponibles dans ce projet, leur utilisation, et ce qu'ils produisent.

## üéØ Vue d'ensemble

Les scripts sont organis√©s en **5 phases num√©rot√©es** qui suivent le workflow logique du projet :

```
0Ô∏è‚É£ Installation & Aide
    ‚Üì
1Ô∏è‚É£ G√©n√©ration des dates
    ‚Üì
2Ô∏è‚É£ Scraping des h√¥tels
    ‚Üì
3Ô∏è‚É£ G√©n√©ration des cartes
    ‚Üì
4Ô∏è‚É£ Visualisation web
```

---

## üîß PHASE 0 : Installation & Aide

### `npm run 0:install`

**√Ä quoi √ßa sert :** Installe toutes les d√©pendances du projet

**Commande :** `npm run 0:install`

**Ce que √ßa fait :**
- Lit le fichier `package.json`
- T√©l√©charge et installe toutes les d√©pendances (Puppeteer, Express, ExcelJS, etc.)
- Cr√©e le dossier `node_modules/`

**Fichiers d'entr√©e :**
- `package.json`

**Fichiers de sortie :**
- `node_modules/` (dossier cr√©√©)
- `package-lock.json` (cr√©√©/mis √† jour)

**Dur√©e :** ~30 secondes √† 2 minutes (selon la connexion)

**Quand l'utiliser :**
- Premi√®re fois que vous clonez le projet
- Apr√®s avoir modifi√© `package.json`
- Si des d√©pendances sont manquantes

**Exemple de sortie console :**
```
added 245 packages, and audited 246 packages in 45s

32 packages are looking for funding
  run `npm fund` for details

found 0 vulnerabilities
```

---

### `npm run 0:help`

**√Ä quoi √ßa sert :** Affiche l'aide compl√®te de tous les scripts disponibles

**Commande :** `npm run 0:help`

**Ce que √ßa fait :**
- Affiche un r√©sum√© format√© de tous les scripts
- Organis√© par phase avec descriptions

**Dur√©e :** Instantan√©

**Quand l'utiliser :**
- Quand vous avez oubli√© une commande
- Pour voir rapidement tous les scripts disponibles

**Exemple de sortie console :**
```
üìã SCRIPTS DISPONIBLES:

üîß PHASE 0 - Installation:
  npm run 0:install - Installe les d√©pendances

üìÖ PHASE 1 - G√©n√©ration des dates:
  npm run 1:dates - G√©n√®re Dates.json (interactif)
  npm run 1:dates-check - V√©rifie les dates g√©n√©r√©es

üï∑Ô∏è  PHASE 2 - Scraping:
  npm run 2:scrape - Lance le scraping complet
  npm run 2:scrape-test - Test de scraping

üó∫Ô∏è  PHASE 3 - G√©n√©ration des cartes:
  npm run 3:map-resume - G√©n√®re resultat.xlsx
  npm run 3:map-data - G√©n√®re mapData.js
  npm run 3:map-all - Ex√©cute resume + data

üåê PHASE 4 - Serveur web:
  npm start - D√©marre le serveur (port 3000)
  npm run 4:start - Alias de start

‚úÖ V√âRIFICATIONS:
  npm run check:cities - Liste les villes configur√©es
  npm run check:results - Liste les fichiers Excel g√©n√©r√©s
  npm run check:dates - Affiche les dates

üîß UTILITAIRES:
  npm run geocode - G√©ocodage avec API Ninja
```

---

## üìÖ PHASE 1 : G√©n√©ration des dates

### `npm run 1:dates`

**√Ä quoi √ßa sert :** G√©n√®re le fichier `Dates.json` avec toutes les dates de scraping

**Commande :** `npm run 1:dates`

**Ce que √ßa fait :**
1. Vous demande : "Dans combien de mois voulez-vous voir les p√©riodes ?"
2. Calcule tous les vendredis du mois sp√©cifi√©
3. Pour chaque vendredi, cr√©e 3 plages de dates :
   - Type 1 : Weekend (vendredi ‚Üí dimanche, 2 jours)
   - Type 2 : Semaine (vendredi ‚Üí vendredi, 7 jours)
   - Type 3 : 2 Semaines (vendredi ‚Üí vendredi, 14 jours)
4. Fusionne avec les dates du fichier `datesAdditionnelles.csv` (si il existe)
5. Supprime les dates pass√©es
6. √âlimine les doublons
7. Trie par type puis par date

**Fichiers d'entr√©e :**
- `src/dates/datesAdditionnelles.csv` (optionnel)

**Fichiers de sortie :**
- `src/scraping/json/Dates.json` (cr√©√©/√©cras√©)

**Dur√©e :** 2-5 secondes

**Quand l'utiliser :**
- Avant chaque nouvelle campagne de scraping
- Pour g√©n√©rer les dates du mois prochain
- Quand vous ajoutez des dates dans `datesAdditionnelles.csv`

**Exemple de sortie console :**
```
Dans combien de mois voulez-vous voir les p√©riodes ? 2
D√©but du traitement...
Objects r√©cup√©r√©s de getDates.js: 12
R√©sultats r√©cup√©r√©s de remplirJSON.js: 3
Date d'aujourd'hui: 2025-01-10
Nombre de dates supprim√©es: 2
Fusion des tableaux...
Nombre total d'√©l√©ments avant d√©duplication: 15
Nombre d'√©l√©ments apr√®s d√©duplication: 13
Tri termin√©
Nombre total de dates apr√®s fusion et d√©duplication: 13
Les dates finales ont √©t√© enregistr√©es dans Dates.json
Traitement termin√©.
```

**Fichier Dates.json g√©n√©r√© (extrait) :**
```json
[
  {
    "date": {
      "fromDate": "2025-02-07",
      "toDate": "2025-02-09",
      "type": 1
    }
  },
  {
    "date": {
      "fromDate": "2025-02-14",
      "toDate": "2025-02-16",
      "type": 1
    }
  },
  ...
]
```

---

### `npm run 1:dates-check`

**√Ä quoi √ßa sert :** Affiche les 10 premi√®res dates du fichier `Dates.json`

**Commande :** `npm run 1:dates-check`

**Ce que √ßa fait :**
- Lit le fichier `Dates.json`
- Affiche le nombre total de dates
- Liste les 10 premi√®res dates avec leurs types

**Fichiers d'entr√©e :**
- `src/scraping/json/Dates.json`

**Dur√©e :** Instantan√©

**Quand l'utiliser :**
- Apr√®s avoir g√©n√©r√© les dates avec `1:dates`
- Pour v√©rifier rapidement quelles dates seront scrap√©es

**Exemple de sortie console :**
```
üìÖ DATES CONFIGUR√âES: 36
  1. 2025-02-07 ‚Üí 2025-02-09 - Type 1
  2. 2025-02-07 ‚Üí 2025-02-14 - Type 2
  3. 2025-02-07 ‚Üí 2025-02-21 - Type 3
  4. 2025-02-14 ‚Üí 2025-02-16 - Type 1
  5. 2025-02-14 ‚Üí 2025-02-21 - Type 2
  6. 2025-02-14 ‚Üí 2025-02-28 - Type 3
  7. 2025-02-21 ‚Üí 2025-02-23 - Type 1
  8. 2025-02-21 ‚Üí 2025-02-28 - Type 2
  9. 2025-02-21 ‚Üí 2025-03-07 - Type 3
  10. 2025-02-28 ‚Üí 2025-03-02 - Type 1
  ... et 26 autres dates
```

---

## üï∑Ô∏è PHASE 2 : Scraping

### `npm run 2:scrape`

**√Ä quoi √ßa sert :** Lance le scraping complet de toutes les villes et dates

**Commande :** `npm run 2:scrape`

**Ce que √ßa fait :**
1. Lit la liste des villes depuis `villesDeDestinations.xlsx`
2. Lit les dates depuis `Dates.json`
3. Pour chaque ville :
   - Pour chaque date :
     - Lance un navigateur Puppeteer
     - Navigue vers TravelAdvantage.com avec les param√®tres
     - Attend le chargement des h√¥tels
     - Prend une capture d'√©cran
     - Extrait les donn√©es des h√¥tels (nom, prix, r√©duction, etc.)
     - D√©duplique les h√¥tels (garde les meilleures offres)
     - Filtre les valeurs aberrantes (prix > 2√ó moyenne)
     - Calcule les statistiques
     - √âcrit dans un fichier Excel par ville
4. D√©lai d'1 seconde entre chaque scraping

**Fichiers d'entr√©e :**
- `src/scraping/villesDeDestinations.xlsx`
- `src/scraping/json/Dates.json`

**Fichiers de sortie :**
- `src/scraping/saveData/datasVilles/{ville}.xlsx` (un par ville)
- `src/scraping/json/hotels_data.json` (temporaire, √©cras√© √† chaque it√©ration)
- `src/scraping/json/saved_hotels.json` (cumulatif)
- `src/scraping/json/statistiques.json` (cumulatif)
- `src/scraping/saveData/images/screenshots/{ville}/screenshots_{date}/` (captures d'√©cran)

**Dur√©e :**
- ~3-5 secondes par ville/date
- **Exemple :** 50 villes √ó 36 dates = 1800 scrapes = **1h30 √† 2h30**

**Quand l'utiliser :**
- Apr√®s avoir g√©n√©r√© les dates avec `1:dates`
- Une fois par semaine pour mettre √† jour les donn√©es
- Quand vous voulez scraper de nouvelles villes

**‚ö†Ô∏è Important :**
- Le script peut tourner plusieurs heures
- Ne pas interrompre sauf urgence
- En cas d'erreur sur une ville/date, le script continue automatiquement
- Les donn√©es sont sauvegard√©es progressivement (pas de perte en cas d'arr√™t)

**Exemple de sortie console :**
```
Scraping pour Paris du 2025-02-07 au 2025-02-09
moyenne de la page : 245.50
Donn√©es ajout√©es au fichier Excel: src/scraping/saveData/datasVilles/Paris.xlsx

Scraping pour Paris du 2025-02-07 au 2025-02-14
moyenne de la page : 312.75
Donn√©es ajout√©es au fichier Excel: src/scraping/saveData/datasVilles/Paris.xlsx

Scraping pour Londres du 2025-02-07 au 2025-02-09
moyenne de la page : 198.30
Donn√©es ajout√©es au fichier Excel: src/scraping/saveData/datasVilles/Londres.xlsx

...
```

---

### `npm run 2:scrape-test`

**√Ä quoi √ßa sert :** Test de scraping pour v√©rifier que le scraper fonctionne

**Commande :** `npm run 2:scrape-test`

**Ce que √ßa fait :**
- Lance le script `scrapeHotels.js` directement
- Utile pour tester ou d√©bugger le scraping

**‚ö†Ô∏è Note :** Ce script n√©cessite des param√®tres cod√©s en dur dans le fichier (voir ligne 183 de `scrapeHotels.js`)

**Dur√©e :** ~3-5 secondes

**Quand l'utiliser :**
- Pour tester le scraping avant de lancer le complet
- Pour d√©bugger des probl√®mes de scraping
- Pour v√©rifier que Puppeteer fonctionne correctement

---

## üó∫Ô∏è PHASE 3 : G√©n√©ration des cartes

### `npm run 3:map-resume`

**√Ä quoi √ßa sert :** Agr√®ge tous les fichiers Excel des villes en un seul fichier r√©sum√©

**Commande :** `npm run 3:map-resume`

**Ce que √ßa fait :**
1. Lit tous les fichiers Excel dans `src/scraping/saveData/datasVilles/`
2. Pour chaque ville, pour chaque mois :
   - Extrait les cellules B1, C1, D1 (pourcentages max de r√©duction)
   - Ces cellules contiennent : Weekend%, Semaine%, 2 Semaines%
3. Cr√©e un fichier `resultat.xlsx` avec un onglet par mois
4. Chaque onglet contient : Ville | Weekend (%) | Semaine (%) | 2 Semaines (%)
5. Met en gras les pourcentages > 40%

**Fichiers d'entr√©e :**
- `src/scraping/saveData/datasVilles/*.xlsx` (tous les fichiers)

**Fichiers de sortie :**
- `src/MapLeaflet/resultat.xlsx` (cr√©√©/√©cras√©)

**Dur√©e :** 1-3 secondes

**Quand l'utiliser :**
- Apr√®s un scraping complet
- Avant de g√©n√©rer les donn√©es de carte
- Automatiquement ex√©cut√© au d√©marrage du serveur

**Exemple de sortie console :**
```
Le fichier resultat.xlsx a √©t√© cr√©√© avec succ√®s.
```

**Structure du fichier resultat.xlsx :**
```
Onglet "F√©vrier_2025":
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Ville   ‚îÇ Weekend(%) ‚îÇ Semaine(%) ‚îÇ 2 Semaines(%) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Paris    ‚îÇ    35      ‚îÇ    42      ‚îÇ      48        ‚îÇ  (48 en gras)
‚îÇ Londres  ‚îÇ    28      ‚îÇ    31      ‚îÇ      38        ‚îÇ
‚îÇ Monaco   ‚îÇ    45      ‚îÇ    52      ‚îÇ      58        ‚îÇ  (45, 52, 58 en gras)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### `npm run 3:map-data`

**√Ä quoi √ßa sert :** Transforme `resultat.xlsx` en fichier JavaScript pour la carte Leaflet

**Commande :** `npm run 3:map-data`

**Ce que √ßa fait :**
1. Lit le fichier `resultat.xlsx`
2. Pour chaque ville, cherche les coordonn√©es GPS dans `villesDeDestinations.xlsx`
3. Cr√©e un objet JavaScript organis√© par mois
4. Chaque ville contient : nom, pays, latitude, longitude, pourcentages[3]
5. √âcrit le fichier `mapData.js`

**Fichiers d'entr√©e :**
- `src/MapLeaflet/resultat.xlsx`
- `src/scraping/villesDeDestinations.xlsx`

**Fichiers de sortie :**
- `src/MapLeaflet/mapData.js` (cr√©√©/√©cras√©)

**Dur√©e :** 1-2 secondes

**Quand l'utiliser :**
- Apr√®s avoir g√©n√©r√© `resultat.xlsx`
- Avant de d√©marrer le serveur web
- Automatiquement ex√©cut√© au d√©marrage du serveur

**Exemple de sortie console :**
```
Le fichier mapData.js a √©t√© cr√©√© avec succ√®s.
```

**Structure du fichier mapData.js :**
```javascript
const mapData = {
  "F√©vrier_2025": [
    {
      "ville": "Paris",
      "country": "France",
      "lat": 48.8566,
      "lon": 2.3522,
      "pourcentages": [35, 42, 48]
    },
    {
      "ville": "Londres",
      "country": "Royaume-Uni",
      "lat": 51.5074,
      "lon": -0.1278,
      "pourcentages": [28, 31, 38]
    },
    ...
  ],
  "Mars_2025": [ ... ]
};
```

---

### `npm run 3:map-all`

**√Ä quoi √ßa sert :** Ex√©cute `3:map-resume` puis `3:map-data` en une seule commande

**Commande :** `npm run 3:map-all`

**Ce que √ßa fait :**
- Lance `npm run 3:map-resume`
- Attend la fin
- Lance `npm run 3:map-data`

**Dur√©e :** 2-5 secondes

**Quand l'utiliser :**
- Apr√®s un scraping complet
- Pour r√©g√©n√©rer toutes les donn√©es de carte d'un coup
- Quand vous voulez √™tre s√ªr que tout est √† jour

**Exemple de sortie console :**
```
> npm run 3:map-resume

Le fichier resultat.xlsx a √©t√© cr√©√© avec succ√®s.

> npm run 3:map-data

Le fichier mapData.js a √©t√© cr√©√© avec succ√®s.
```

---

## üåê PHASE 4 : Serveur web

### `npm start` ou `npm run 4:start`

**√Ä quoi √ßa sert :** D√©marre le serveur web Express pour visualiser les r√©sultats

**Commande :** `npm start` (ou `npm run 4:start`)

**Ce que √ßa fait :**
1. **Avant le d√©marrage :**
   - Ex√©cute automatiquement `3:map-resume` (g√©n√®re resultat.xlsx)
   - Ex√©cute automatiquement `3:map-data` (g√©n√®re mapData.js)
2. **D√©marrage du serveur :**
   - D√©marre Express sur le port 3000
   - Sert les fichiers statiques depuis `src/`
   - Active les routes API :
     - `GET /` ‚Üí interface carte
     - `POST /saveSelectedCities` ‚Üí enregistre s√©lection utilisateur
     - `GET /getHotelsData` ‚Üí retourne d√©tails des h√¥tels
     - `GET /getCitiesData` ‚Üí retourne coordonn√©es des villes
     - `GET /templateBrevo` ‚Üí template email

**Fichiers d'entr√©e :**
- `src/MapLeaflet/resultat.xlsx`
- `src/MapLeaflet/mapData.js`
- `src/MapLeaflet/index2.html`
- `src/assets/js/villesDeDestinations.json`

**Dur√©e :** 5-10 secondes pour d√©marrer

**Quand l'utiliser :**
- Apr√®s un scraping pour visualiser les r√©sultats
- Pour consulter les donn√©es sur la carte interactive
- Pour g√©n√©rer les templates d'email

**Exemple de sortie console :**
```
Changement de r√©pertoire vers MapLeaflet...
Chemin du r√©pertoire MapLeaflet : C:\...\src\MapLeaflet
Ex√©cution de index1.js...
Le fichier resultat.xlsx a √©t√© cr√©√© avec succ√®s.
index1.js ex√©cut√© avec succ√®s.
Ex√©cution de generateMap.js...
Le fichier mapData.js a √©t√© cr√©√© avec succ√®s.
generateMap.js ex√©cut√© avec succ√®s.
Retour au r√©pertoire racine...
processExcelData import√© : function
Serveur en cours d'ex√©cution sur http://localhost:3000
```

**Acc√®s :**
- Ouvrir le navigateur ‚Üí `http://localhost:3000`
- Interface carte interactive avec :
  - S√©lecteur de mois (dropdown)
  - S√©lecteur de type (Weekend/Semaine/2 Semaines)
  - Marqueurs cliquables sur la carte
  - Affichage des pourcentages de r√©duction

**Pour arr√™ter le serveur :** `Ctrl + C` dans le terminal

---

## ‚úÖ SCRIPTS DE V√âRIFICATION

### `npm run check:cities`

**√Ä quoi √ßa sert :** Liste toutes les villes configur√©es dans le fichier Excel

**Commande :** `npm run check:cities`

**Ce que √ßa fait :**
- Lit `villesDeDestinations.xlsx`
- Compte le nombre de villes
- Affiche la liste : num√©ro, nom, pays

**Fichiers d'entr√©e :**
- `src/scraping/villesDeDestinations.xlsx`

**Dur√©e :** Instantan√©

**Quand l'utiliser :**
- Avant de lancer un scraping
- Pour v√©rifier quelles villes seront scrap√©es
- Apr√®s avoir ajout√© une nouvelle ville

**Exemple de sortie console :**
```
üèôÔ∏è  VILLES CONFIGUR√âES: 8
  1. Paris, France
  2. Londres, Royaume-Uni
  3. Monaco, Monaco
  4. Barcelone, Espagne
  5. Rome, Italie
  6. Berlin, Allemagne
  7. Amsterdam, Pays-Bas
  8. Bruxelles, Belgique
```

---

### `npm run check:results`

**√Ä quoi √ßa sert :** Liste tous les fichiers Excel g√©n√©r√©s par le scraping

**Commande :** `npm run check:results`

**Ce que √ßa fait :**
- Lit le dossier `src/scraping/saveData/datasVilles/`
- Liste tous les fichiers `.xlsx`
- Affiche le nombre total

**Fichiers d'entr√©e :**
- Dossier `src/scraping/saveData/datasVilles/`

**Dur√©e :** Instantan√©

**Quand l'utiliser :**
- Apr√®s un scraping pour v√©rifier que tout s'est bien pass√©
- Pour voir quelles villes ont √©t√© scrap√©es
- Pour identifier les villes manquantes

**Exemple de sortie console :**
```
üìä FICHIERS EXCEL G√âN√âR√âS: 8
  1. Paris.xlsx
  2. Londres.xlsx
  3. Monaco.xlsx
  4. Barcelone.xlsx
  5. Rome.xlsx
  6. Berlin.xlsx
  7. Amsterdam.xlsx
  8. Bruxelles.xlsx
```

**Si aucun r√©sultat :**
```
‚ùå Aucun r√©sultat trouv√©
```

---

### `npm run check:dates`

**√Ä quoi √ßa sert :** Affiche les statistiques sur les dates configur√©es

**Commande :** `npm run check:dates`

**Ce que √ßa fait :**
- Lit `Dates.json`
- Compte le nombre total de dates
- Compte le nombre de dates par type (Weekend, Semaine, 2 Semaines)

**Fichiers d'entr√©e :**
- `src/scraping/json/Dates.json`

**Dur√©e :** Instantan√©

**Quand l'utiliser :**
- Apr√®s avoir g√©n√©r√© les dates
- Pour v√©rifier la r√©partition par type
- Pour estimer la dur√©e du scraping

**Exemple de sortie console :**
```
üìÖ Total: 36 dates
  - Weekend: 12
  - Semaine: 12
  - 2 Semaines: 12
```

---

## üîß UTILITAIRES

### `npm run geocode`

**√Ä quoi √ßa sert :** Utilitaire de g√©ocodage utilisant l'API Ninja

**Commande :** `npm run geocode`

**Ce que √ßa fait :**
- Lance le script `indexNinjasAPI.js`
- Permet de r√©cup√©rer les coordonn√©es GPS d'une ville
- Utile pour ajouter de nouvelles villes √† `villesDeDestinations.xlsx`

**Dur√©e :** Variable selon l'utilisation

**Quand l'utiliser :**
- Quand vous voulez ajouter une nouvelle ville
- Pour r√©cup√©rer les coordonn√©es GPS d'une adresse

---

## üéØ WORKFLOWS TYPIQUES

### Workflow 1 : Premi√®re utilisation

```bash
# 1. Installer les d√©pendances
npm run 0:install

# 2. Voir les scripts disponibles
npm run 0:help

# 3. V√©rifier les villes configur√©es
npm run check:cities

# 4. G√©n√©rer les dates
npm run 1:dates
# (Entrer "1" pour le mois prochain)

# 5. V√©rifier les dates
npm run 1:dates-check

# 6. Lancer le scraping
npm run 2:scrape
# ‚è≥ Attendre 1-2 heures

# 7. V√©rifier les r√©sultats
npm run check:results

# 8. D√©marrer le serveur
npm start

# 9. Ouvrir le navigateur
# http://localhost:3000
```

---

### Workflow 2 : Mise √† jour hebdomadaire

```bash
# Les dates sont d√©j√† configur√©es, on re-scrape avec les m√™mes dates
npm run 2:scrape

# Quand c'est fini, d√©marrer le serveur pour voir les nouvelles donn√©es
npm start
```

---

### Workflow 3 : Nouveau mois

```bash
# 1. G√©n√©rer les dates du nouveau mois
npm run 1:dates
# (Entrer le num√©ro du mois)

# 2. V√©rifier
npm run 1:dates-check

# 3. Scraper
npm run 2:scrape

# 4. Visualiser
npm start
```

---

### Workflow 4 : Ajouter une ville

```bash
# 1. √âditer villesDeDestinations.xlsx
# Ajouter : nom | pays | latitude | longitude | code pays

# 2. V√©rifier que la ville appara√Æt
npm run check:cities

# 3. Scraper (toutes les villes, mais d√©duplication √©vite les doublons)
npm run 2:scrape

# 4. V√©rifier que le fichier Excel a √©t√© cr√©√©
npm run check:results

# 5. Visualiser
npm start
```

---

### Workflow 5 : R√©g√©n√©rer uniquement les cartes

```bash
# Si vous avez modifi√© manuellement des fichiers Excel
npm run 3:map-all

# Puis d√©marrer le serveur
npm start
```

---

## ‚ö†Ô∏è D√âPANNAGE

### Probl√®me : "Cannot find module 'Dates.json'"

**Solution :**
```bash
npm run 1:dates
```
Vous devez d'abord g√©n√©rer le fichier Dates.json.

---

### Probl√®me : "Aucun r√©sultat trouv√©" apr√®s scraping

**Causes possibles :**
1. Le scraping n'est pas encore termin√©
2. Une erreur s'est produite pendant le scraping
3. Le dossier `saveData/datasVilles` n'existe pas

**Solution :**
- V√©rifier les logs du scraping
- Relancer `npm run 2:scrape`

---

### Probl√®me : Le serveur ne d√©marre pas

**Erreur possible :** "Address already in use"

**Solution :**
- Le port 3000 est d√©j√† utilis√©
- Tuer le processus existant ou changer le port dans `server.js`

---

### Probl√®me : Une ville n'appara√Æt pas sur la carte

**Causes possibles :**
1. Les coordonn√©es GPS sont manquantes dans `villesDeDestinations.xlsx`
2. Le nom de la ville ne correspond pas exactement entre les fichiers

**Solution :**
- V√©rifier `villesDeDestinations.xlsx`
- V√©rifier que le nom de la ville est exactement le m√™me partout
- Relancer `npm run 3:map-all` puis `npm start`

---

### Probl√®me : Puppeteer ne se lance pas

**Erreur possible :** "Failed to launch browser"

**Solutions :**
- R√©installer Puppeteer : `npm install puppeteer`
- V√©rifier que Chrome/Chromium est install√©
- Sur Linux : installer les d√©pendances syst√®me de Chrome

---

## üìä ESTIMATION DES DUR√âES

| Action | Script | Dur√©e estim√©e |
|--------|--------|---------------|
| Installation | `0:install` | 30s - 2min |
| G√©n√©ration dates | `1:dates` | 2-5s |
| Scraping (1 ville √ó 36 dates) | `2:scrape` | 2-3 min |
| Scraping (50 villes √ó 36 dates) | `2:scrape` | 1h30 - 2h30 |
| G√©n√©ration r√©sum√© | `3:map-resume` | 1-3s |
| G√©n√©ration carte | `3:map-data` | 1-2s |
| D√©marrage serveur | `start` | 5-10s |

---

## üí° ASTUCES

1. **Toujours v√©rifier avant de scraper :**
   ```bash
   npm run check:cities
   npm run 1:dates-check
   ```

2. **Workflow rapide avec une seule commande :**
   ```bash
   npm run 1:dates && npm run 2:scrape && npm start
   ```
   (Attention : le scraping peut √™tre tr√®s long)

3. **Voir les logs en temps r√©el :**
   Le scraping affiche la progression dans la console. Ne fermez pas le terminal !

4. **Sauvegarder les r√©sultats :**
   Les fichiers Excel dans `saveData/datasVilles/` sont vos donn√©es principales. Faites des backups r√©guliers !

5. **Consulter CLAUDE.md :**
   Pour plus de d√©tails sur l'architecture, voir le fichier [CLAUDE.md](CLAUDE.md)

---

## üìû AIDE SUPPL√âMENTAIRE

- **Guide complet :** `npm run 0:help`
- **Architecture du projet :** Voir `CLAUDE.md`
- **Structure des donn√©es :** Voir section "Emplacements importants des donn√©es" dans `CLAUDE.md`
