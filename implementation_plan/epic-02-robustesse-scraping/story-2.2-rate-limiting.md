# Story 2.2 - D√©tection et Gestion Rate Limiting

> **Epic:** [2 - Robustesse Scraping](README.md)
> **Priorit√©:** üü† P1
> **Complexit√©:** M (2-4h)
> **Statut:** TODO
> **D√©pendances:** [Story 2.1](story-2.1-retry-logic.md)

---

## Contexte

Les sites web comme TravelAdvantage.com peuvent d√©tecter le scraping et bloquer les requ√™tes via des codes HTTP 429 (Too Many Requests) ou 403 (Forbidden). Sans gestion de ces cas, le scraping continue de tenter en vain.

## Probl√®me

Actuellement, aucune d√©tection ni gestion du rate limiting :

```javascript
// scrapeHotels.js - page.goto() sans interception des r√©ponses HTTP
await page.goto(url, { timeout: 60000 });
// Si 429 ou 403, la page charge mais pas de donn√©es
// Le s√©lecteur timeout apr√®s 240s sans savoir pourquoi
```

### Sympt√¥mes

- Timeout √† r√©p√©tition sur plusieurs villes cons√©cutives
- Page qui charge mais sans r√©sultats
- Possibles messages d'erreur sur la page (captcha, blocage)

## Solution Propos√©e

### Partie 1: Interception des r√©ponses HTTP

```javascript
// Dans scrapeHotels.js, apr√®s cr√©ation de la page

// Intercepter les r√©ponses pour d√©tecter rate limiting
let isRateLimited = false;
let httpStatus = 200;

page.on('response', response => {
    const status = response.status();
    const url = response.url();

    // V√©rifier la r√©ponse principale
    if (url.includes('traveladvantage.com/hotel/search')) {
        httpStatus = status;

        if (status === 429) {
            console.log('[RATE] HTTP 429 - Too Many Requests d√©tect√©');
            isRateLimited = true;
        } else if (status === 403) {
            console.log('[RATE] HTTP 403 - Forbidden d√©tect√©');
            isRateLimited = true;
        }
    }
});
```

### Partie 2: V√©rification avant extraction

```javascript
// Apr√®s page.goto(), v√©rifier le status
await page.goto(url, { timeout: 60000 });

if (isRateLimited) {
    const error = new Error(`Rate limited: HTTP ${httpStatus}`);
    error.isRateLimited = true;
    throw error;
}

// V√©rifier aussi le contenu de la page pour captcha/blocage
const pageContent = await page.content();
if (pageContent.includes('captcha') ||
    pageContent.includes('blocked') ||
    pageContent.includes('too many requests')) {
    const error = new Error('Rate limited: Page content indicates blocking');
    error.isRateLimited = true;
    throw error;
}
```

### Partie 3: Gestion dans scrapeWithRetry (Story 2.1)

Modifier `classifyError()` pour mieux g√©rer le rate limiting :

```javascript
function classifyError(error) {
    // ... code existant ...

    // D√©tection explicite rate limiting
    if (error.isRateLimited ||
        message.includes('429') ||
        message.includes('403') ||
        message.includes('rate limit') ||
        message.includes('too many requests')) {
        return {
            type: ErrorType.RATE_LIMITED,
            retryable: true,
            extraDelay: 60000,  // 60 secondes de pause
            pauseAllScraping: true  // Pause globale recommand√©e
        };
    }

    // ... reste du code ...
}
```

### Partie 4: Pause globale si rate limit d√©tect√©

```javascript
// Dans index.js, variable globale
let globalRateLimitPause = false;

// Dans la boucle de scraping
if (globalRateLimitPause) {
    console.log('[RATE] Pause globale active, attente 2 minutes...');
    await delay(120000);
    globalRateLimitPause = false;
}

try {
    await scrapeWithRetry(scrapeParams);
} catch (error) {
    if (error.isRateLimited) {
        globalRateLimitPause = true;
        console.log('[RATE] Rate limiting d√©tect√©, activation pause globale');
    }
}
```

---

## Fichiers √† Modifier

| Fichier | Modification | Lignes |
|---------|--------------|--------|
| `src/scraping/scrapeHotels.js` | Ajouter interception r√©ponses HTTP | Apr√®s `newPage()` |
| `src/scraping/scrapeHotels.js` | V√©rifier contenu page (captcha) | Apr√®s `goto()` |
| `src/scraping/index.js` | Am√©liorer `classifyError()` | Dans fonction |
| `src/scraping/index.js` | Ajouter gestion pause globale | Boucle scraping |

---

## Crit√®res d'Acceptation

- [ ] HTTP 429 est d√©tect√© et logg√© clairement
- [ ] HTTP 403 est d√©tect√© et logg√© clairement
- [ ] Le scraping attend 60s minimum apr√®s d√©tection rate limit
- [ ] Une pause globale est activ√©e pour prot√©ger les requ√™tes suivantes
- [ ] Les pages avec captcha/blocage sont d√©tect√©es
- [ ] Le retry reprend apr√®s la pause
- [ ] Log clair du nombre de rate limits rencontr√©s en fin de run

---

## Tests Manuels

1. **Test d√©tection 429:**
   ```javascript
   // Difficile √† reproduire naturellement
   // Option: utiliser un proxy/mock qui retourne 429
   // Ou tester en r√©duisant fortement le d√©lai entre requ√™tes
   ```

2. **Test d√©tection contenu page:**
   ```javascript
   // Injecter temporairement une v√©rification:
   // if (pageContent.includes('test_block')) throw ...
   // V√©rifier que l'erreur est bien classifi√©e
   ```

3. **Test pause globale:**
   ```javascript
   // Simuler une erreur rate limited sur la ville 1
   // V√©rifier que les villes 2-5 attendent la pause
   // V√©rifier que le scraping reprend apr√®s
   ```

---

## Indicateurs de Rate Limiting

### Signes dans les logs

```
[RATE] HTTP 429 - Too Many Requests d√©tect√©
[RATE] Rate limiting d√©tect√©, activation pause globale
[RATE] Pause globale active, attente 2 minutes...
```

### Signes sur la page

- Page blanche ou erreur
- Message "Too many requests"
- Captcha affich√©
- Redirection vers page de blocage

---

## Strat√©gies Compl√©mentaires

### Rotation User-Agent (optionnel)

```javascript
const userAgents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36...',
    // ...
];

await page.setUserAgent(userAgents[Math.floor(Math.random() * userAgents.length)]);
```

### D√©lai al√©atoire entre requ√™tes

```javascript
// Au lieu de delay(1000) fixe
const randomDelay = 1000 + Math.random() * 2000; // 1-3 secondes
await delay(randomDelay);
```

---

## Notes d'Impl√©mentation

- La d√©tection HTTP 429/403 n√©cessite l'interception des r√©ponses Puppeteer
- La d√©tection par contenu est un fallback si le site retourne 200 avec page d'erreur
- La pause globale emp√™che de "griller" toutes les tentatives de retry
- Consid√©rer sauvegarder l'√©tat avant pause (voir Story 2.3) pour reprise

---

## Liens

- [Epic 2 - Robustesse Scraping](README.md)
- [Story 2.1 - Retry Logic](story-2.1-retry-logic.md) (pr√©-requis)
- [Story 2.3 - Progression State](story-2.3-progression-state.md) (compl√©mentaire)
- [INDEX](../INDEX.md)
