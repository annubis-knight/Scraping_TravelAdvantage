# Story 8.1 - ParallÃ©lisation du Scraping

> **Epic:** [8 - Performance & Optimisation](README.md)
> **PrioritÃ©:** ğŸŸ¢ P3
> **ComplexitÃ©:** XL (> 8h)
> **Statut:** TODO

---

## Contexte

Le scraping actuel est purement sÃ©quentiel : une ville aprÃ¨s l'autre, une date aprÃ¨s l'autre. Cela entraÃ®ne des temps d'exÃ©cution prohibitifs pour de nombreuses destinations.

## ProblÃ¨me

```javascript
// Actuellement dans index.js
for (const cityData of cities) {           // SÃ©quentiel
    for (const date of dates) {            // SÃ©quentiel
        await scrapeHotels(...);           // Bloquant
        await delay(1000);
    }
}
// 20 villes Ã— 3 dates Ã— 5min = 5 heures !
```

### Impact

| Nombre de villes | Temps sÃ©quentiel | Temps parallÃ¨le (3 workers) |
|------------------|------------------|----------------------------|
| 5 | ~25 min | ~10 min |
| 10 | ~50 min | ~20 min |
| 20 | ~100 min | ~35 min |
| 50 | ~250 min | ~85 min |

## Solution ProposÃ©e

ImplÃ©menter un systÃ¨me de workers parallÃ¨les avec une limite configurable.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Queue Manager                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Queue: [                                                  â”‚
â”‚     {ville: Paris, date: 01/02, type: 1},                   â”‚
â”‚     {ville: Paris, date: 01/02, type: 2},                   â”‚
â”‚     {ville: Londres, date: 01/02, type: 1},                 â”‚
â”‚     ...                                                     â”‚
â”‚   ]                                                         â”‚
â”‚                                                             â”‚
â”‚   Workers actifs: 3 / 3 max                                 â”‚
â”‚   ComplÃ©tÃ©s: 12 / 45                                        â”‚
â”‚   Ã‰checs: 1                                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Code - Gestionnaire de Queue

```javascript
// src/scraping/parallelScraper.js

const { scrapeWithRetry } = require('./index'); // Story 2.1

class ParallelScraper {
    constructor(options = {}) {
        this.maxWorkers = options.maxWorkers || 3;
        this.delayBetweenStarts = options.delayBetweenStarts || 5000; // 5s entre dÃ©marrages
        this.queue = [];
        this.activeWorkers = 0;
        this.results = { success: [], failed: [] };
    }

    /**
     * Ajoute les tÃ¢ches Ã  la queue
     */
    addTasks(cities, dates) {
        for (const city of cities) {
            for (const date of dates) {
                this.queue.push({
                    ville: city.ville,
                    pays: city.country,
                    lat: city.lat,
                    lon: city.lon,
                    fromDate: date.date.fromDate,
                    toDate: date.date.toDate,
                    type: date.date.type
                });
            }
        }
        console.log(`[PARALLEL] ${this.queue.length} tÃ¢ches ajoutÃ©es Ã  la queue`);
    }

    /**
     * Lance le scraping parallÃ¨le
     */
    async run() {
        const startTime = Date.now();
        console.log(`[PARALLEL] DÃ©marrage avec ${this.maxWorkers} workers max`);

        const workers = [];

        // DÃ©marrer les workers avec un dÃ©lai entre chaque
        for (let i = 0; i < this.maxWorkers; i++) {
            if (this.queue.length === 0) break;

            workers.push(this.startWorker(i + 1));

            // DÃ©lai entre les dÃ©marrages pour Ã©viter surcharge
            if (i < this.maxWorkers - 1 && this.queue.length > 0) {
                await this.delay(this.delayBetweenStarts);
            }
        }

        // Attendre que tous les workers terminent
        await Promise.all(workers);

        const duration = ((Date.now() - startTime) / 1000 / 60).toFixed(1);
        console.log(`[PARALLEL] TerminÃ© en ${duration} minutes`);
        console.log(`[PARALLEL] SuccÃ¨s: ${this.results.success.length}, Ã‰checs: ${this.results.failed.length}`);

        return this.results;
    }

    /**
     * Worker qui consomme la queue
     */
    async startWorker(workerId) {
        console.log(`[WORKER ${workerId}] DÃ©marrÃ©`);
        this.activeWorkers++;

        while (this.queue.length > 0) {
            const task = this.queue.shift();
            const taskId = `${task.ville}-${task.fromDate}-T${task.type}`;

            console.log(`[WORKER ${workerId}] Traitement: ${taskId}`);
            console.log(`[PARALLEL] Queue restante: ${this.queue.length}, Workers actifs: ${this.activeWorkers}`);

            try {
                await scrapeWithRetry(task);
                this.results.success.push(taskId);
                console.log(`[WORKER ${workerId}] âœ“ ${taskId}`);
            } catch (error) {
                this.results.failed.push({ taskId, error: error.message });
                console.error(`[WORKER ${workerId}] âœ— ${taskId}: ${error.message}`);
            }

            // DÃ©lai entre les tÃ¢ches d'un mÃªme worker
            await this.delay(2000);
        }

        this.activeWorkers--;
        console.log(`[WORKER ${workerId}] TerminÃ©`);
    }

    delay(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
}

module.exports = { ParallelScraper };
```

### Utilisation dans index.js

```javascript
// Option A: Mode parallÃ¨le
const { ParallelScraper } = require('./parallelScraper');

async function runParallel(cities, dates) {
    const scraper = new ParallelScraper({
        maxWorkers: 3,           // Configurable
        delayBetweenStarts: 5000 // 5s entre dÃ©marrages
    });

    scraper.addTasks(cities, dates);
    const results = await scraper.run();

    // Afficher rÃ©sumÃ©
    console.log('\n=== RÃ‰SUMÃ‰ SCRAPING PARALLÃˆLE ===');
    console.log(`SuccÃ¨s: ${results.success.length}`);
    console.log(`Ã‰checs: ${results.failed.length}`);

    if (results.failed.length > 0) {
        console.log('\nÃ‰checs:');
        results.failed.forEach(f => console.log(`  - ${f.taskId}: ${f.error}`));
    }
}

// Option B: Garder le mode sÃ©quentiel disponible
const args = process.argv.slice(2);
if (args.includes('--parallel')) {
    runParallel(cities, dates);
} else {
    runSequential(cities, dates); // Code actuel
}
```

### Script npm

```json
{
    "scripts": {
        "2:scrape": "node src/scraping/index.js",
        "2:scrape-parallel": "node src/scraping/index.js --parallel",
        "2:scrape-parallel-5": "node src/scraping/index.js --parallel --workers=5"
    }
}
```

---

## Gestion MÃ©moire

### ProblÃ¨me Chrome/Puppeteer

Chaque instance Chrome consomme ~200-500 MB de RAM. Avec 5 workers :
- Minimum: 1 GB RAM
- RecommandÃ©: 2+ GB RAM

### Solution: RÃ©utilisation de navigateur

```javascript
// Alternative: un seul browser, plusieurs pages
class SingleBrowserParallelScraper {
    constructor(maxPages = 3) {
        this.browser = null;
        this.maxPages = maxPages;
    }

    async init() {
        this.browser = await puppeteer.launch({
            headless: false,
            args: ['--no-first-run']
        });
    }

    async scrapeTask(task) {
        const page = await this.browser.newPage();
        try {
            // Configurer la page
            await page.setUserAgent(getRandomUserAgent());
            // ... scraping logic
        } finally {
            await page.close(); // LibÃ©rer la mÃ©moire
        }
    }

    async cleanup() {
        if (this.browser) await this.browser.close();
    }
}
```

---

## Fichiers Ã  Modifier/CrÃ©er

| Fichier | Action | Description |
|---------|--------|-------------|
| `src/scraping/parallelScraper.js` | CrÃ©er | Gestionnaire de queue parallÃ¨le |
| `src/scraping/index.js` | Modifier | Ajouter option --parallel |
| `package.json` | Modifier | Ajouter scripts npm |

---

## CritÃ¨res d'Acceptation

- [ ] `npm run 2:scrape-parallel` lance le scraping en parallÃ¨le
- [ ] Maximum de workers configurable (dÃ©faut: 3)
- [ ] Chaque worker est identifiÃ© dans les logs
- [ ] Queue affiche la progression (X/Y complÃ©tÃ©s)
- [ ] Les Ã©checs sont collectÃ©s et affichÃ©s en fin de run
- [ ] Le mode sÃ©quentiel reste disponible (`npm run 2:scrape`)
- [ ] La consommation mÃ©moire reste raisonnable (< 2 GB pour 3 workers)

---

## Tests

### Test 1: Performance

```bash
# Mesurer le temps sÃ©quentiel
time npm run 2:scrape

# Mesurer le temps parallÃ¨le
time npm run 2:scrape-parallel

# Comparer les rÃ©sultats
```

### Test 2: Gestion d'erreurs

```javascript
// Simuler des Ã©checs alÃ©atoires
// VÃ©rifier que les autres tÃ¢ches continuent
// VÃ©rifier le rapport final
```

### Test 3: MÃ©moire

```bash
# Observer la consommation pendant l'exÃ©cution
# Sur Windows: Task Manager
# Sur Linux: htop ou top
```

---

## DÃ©pendances

| Story | Raison |
|-------|--------|
| [2.1 - Retry Logic](../epic-02-robustesse-scraping/story-2.1-retry-logic.md) | Gestion des erreurs par worker |
| [2.3 - Ã‰tat de progression](../epic-02-robustesse-scraping/story-2.3-progression-state.md) | Reprise aprÃ¨s interruption |
| [2.4 - User-Agent Rotation](../epic-02-robustesse-scraping/story-2.4-user-agent-rotation.md) | Ã‰viter blocage multi-requÃªtes |

---

## Liens

- [Epic 8 - Performance](README.md)
- [INDEX](../INDEX.md)
